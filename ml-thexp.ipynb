{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An investigation of the Universal Approximation Theorem \n",
    "### <u>Neural Networks</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let us first try to learn a simple function using neural networks\n",
    "### f(x) = 2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_for_2_x():\n",
    "    # Given f(x) = 2x, is_f_x defines whether the function is satisfied\n",
    "    data = []\n",
    "    for i in range(1,100):\n",
    "        data.append((i, 2*i, 1)) # True\n",
    "    for j in range(100, 201):\n",
    "        data.append((j, 2*j+12, 0)) # Not true\n",
    "    column_names = [\"first_number\",\"f_x\", \"is_f_x\"]\n",
    "    df = pd.DataFrame(data, columns=column_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_number</th>\n",
       "      <th>f_x</th>\n",
       "      <th>is_f_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_number  f_x  is_f_x\n",
       "0             1    2       1\n",
       "1             2    4       1\n",
       "2             3    6       1\n",
       "3             4    8       1\n",
       "4             5   10       1"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = build_dataset_for_2_x()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.is_f_x.values\n",
    "features = df.drop(columns=['is_f_x']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building nn\n",
    "net = nn.Sequential(nn.Linear(features.shape[1],10), nn.Tanh(), nn.Linear(10, 10), nn.ReLU(),nn.Linear(10, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, shuffle=True, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    net.train()\n",
    "    losses = []\n",
    "    for epoch in range(1,300):\n",
    "        x_train = Variable(torch.from_numpy(features_train)).float()\n",
    "        y_train = Variable(torch.from_numpy(labels_train)).long()\n",
    "        y_pred = net(x_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        print (\"epoch #\", epoch)\n",
    "        print (loss.item())\n",
    "        losses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch # 1\n",
      "0.7367300391197205\n",
      "epoch # 2\n",
      "0.7303361296653748\n",
      "epoch # 3\n",
      "0.7239254713058472\n",
      "epoch # 4\n",
      "0.7181443572044373\n",
      "epoch # 5\n",
      "0.7125107645988464\n",
      "epoch # 6\n",
      "0.7070106267929077\n",
      "epoch # 7\n",
      "0.7022601962089539\n",
      "epoch # 8\n",
      "0.697613000869751\n",
      "epoch # 9\n",
      "0.6930612325668335\n",
      "epoch # 10\n",
      "0.6885976195335388\n",
      "epoch # 11\n",
      "0.6842154264450073\n",
      "epoch # 12\n",
      "0.679901123046875\n",
      "epoch # 13\n",
      "0.6756616830825806\n",
      "epoch # 14\n",
      "0.6714904308319092\n",
      "epoch # 15\n",
      "0.6673827171325684\n",
      "epoch # 16\n",
      "0.6633363962173462\n",
      "epoch # 17\n",
      "0.6593471765518188\n",
      "epoch # 18\n",
      "0.6554096937179565\n",
      "epoch # 19\n",
      "0.6515253186225891\n",
      "epoch # 20\n",
      "0.6476871371269226\n",
      "epoch # 21\n",
      "0.6438924074172974\n",
      "epoch # 22\n",
      "0.6401378512382507\n",
      "epoch # 23\n",
      "0.6364228129386902\n",
      "epoch # 24\n",
      "0.632743239402771\n",
      "epoch # 25\n",
      "0.629095196723938\n",
      "epoch # 26\n",
      "0.6254783868789673\n",
      "epoch # 27\n",
      "0.621890127658844\n",
      "epoch # 28\n",
      "0.6183290481567383\n",
      "epoch # 29\n",
      "0.6147902011871338\n",
      "epoch # 30\n",
      "0.6112762093544006\n",
      "epoch # 31\n",
      "0.607782244682312\n",
      "epoch # 32\n",
      "0.604306697845459\n",
      "epoch # 33\n",
      "0.6008480787277222\n",
      "epoch # 34\n",
      "0.5974061489105225\n",
      "epoch # 35\n",
      "0.5939785242080688\n",
      "epoch # 36\n",
      "0.590563178062439\n",
      "epoch # 37\n",
      "0.5871608853340149\n",
      "epoch # 38\n",
      "0.5837681293487549\n",
      "epoch # 39\n",
      "0.5803866982460022\n",
      "epoch # 40\n",
      "0.5770118236541748\n",
      "epoch # 41\n",
      "0.5736450552940369\n",
      "epoch # 42\n",
      "0.5702843070030212\n",
      "epoch # 43\n",
      "0.5669305324554443\n",
      "epoch # 44\n",
      "0.563581109046936\n",
      "epoch # 45\n",
      "0.5602348446846008\n",
      "epoch # 46\n",
      "0.5568918585777283\n",
      "epoch # 47\n",
      "0.5535529255867004\n",
      "epoch # 48\n",
      "0.550214409828186\n",
      "epoch # 49\n",
      "0.5468780994415283\n",
      "epoch # 50\n",
      "0.5435426831245422\n",
      "epoch # 51\n",
      "0.5402076840400696\n",
      "epoch # 52\n",
      "0.5368724465370178\n",
      "epoch # 53\n",
      "0.5335371494293213\n",
      "epoch # 54\n",
      "0.5302004218101501\n",
      "epoch # 55\n",
      "0.526863157749176\n",
      "epoch # 56\n",
      "0.5235241651535034\n",
      "epoch # 57\n",
      "0.5203472375869751\n",
      "epoch # 58\n",
      "0.5171177387237549\n",
      "epoch # 59\n",
      "0.5140383839607239\n",
      "epoch # 60\n",
      "0.5108181238174438\n",
      "epoch # 61\n",
      "0.5076322555541992\n",
      "epoch # 62\n",
      "0.504521906375885\n",
      "epoch # 63\n",
      "0.5012828707695007\n",
      "epoch # 64\n",
      "0.4981709420681\n",
      "epoch # 65\n",
      "0.49496516585350037\n",
      "epoch # 66\n",
      "0.49173155426979065\n",
      "epoch # 67\n",
      "0.4886270761489868\n",
      "epoch # 68\n",
      "0.4853520691394806\n",
      "epoch # 69\n",
      "0.4822213649749756\n",
      "epoch # 70\n",
      "0.47900426387786865\n",
      "epoch # 71\n",
      "0.47577565908432007\n",
      "epoch # 72\n",
      "0.47265148162841797\n",
      "epoch # 73\n",
      "0.4693550169467926\n",
      "epoch # 74\n",
      "0.46626317501068115\n",
      "epoch # 75\n",
      "0.4629901051521301\n",
      "epoch # 76\n",
      "0.4598100781440735\n",
      "epoch # 77\n",
      "0.45662063360214233\n",
      "epoch # 78\n",
      "0.45335647463798523\n",
      "epoch # 79\n",
      "0.45024755597114563\n",
      "epoch # 80\n",
      "0.44692566990852356\n",
      "epoch # 81\n",
      "0.44384628534317017\n",
      "epoch # 82\n",
      "0.44054439663887024\n",
      "epoch # 83\n",
      "0.4373941123485565\n",
      "epoch # 84\n",
      "0.4341631531715393\n",
      "epoch # 85\n",
      "0.4309445321559906\n",
      "epoch # 86\n",
      "0.4277828335762024\n",
      "epoch # 87\n",
      "0.42450273036956787\n",
      "epoch # 88\n",
      "0.42140501737594604\n",
      "epoch # 89\n",
      "0.418068528175354\n",
      "epoch # 90\n",
      "0.41502851247787476\n",
      "epoch # 91\n",
      "0.41168972849845886\n",
      "epoch # 92\n",
      "0.4086235463619232\n",
      "epoch # 93\n",
      "0.4053281247615814\n",
      "epoch # 94\n",
      "0.40221986174583435\n",
      "epoch # 95\n",
      "0.3989787697792053\n",
      "epoch # 96\n",
      "0.3958335518836975\n",
      "epoch # 97\n",
      "0.39264553785324097\n",
      "epoch # 98\n",
      "0.3894687294960022\n",
      "epoch # 99\n",
      "0.386330246925354\n",
      "epoch # 100\n",
      "0.3831285238265991\n",
      "epoch # 101\n",
      "0.3800373375415802\n",
      "epoch # 102\n",
      "0.3768154978752136\n",
      "epoch # 103\n",
      "0.37376949191093445\n",
      "epoch # 104\n",
      "0.37053343653678894\n",
      "epoch # 105\n",
      "0.36753085255622864\n",
      "epoch # 106\n",
      "0.36428526043891907\n",
      "epoch # 107\n",
      "0.3613244593143463\n",
      "epoch # 108\n",
      "0.35807499289512634\n",
      "epoch # 109\n",
      "0.35515403747558594\n",
      "epoch # 110\n",
      "0.35191038250923157\n",
      "epoch # 111\n",
      "0.34901854395866394\n",
      "epoch # 112\n",
      "0.3458035886287689\n",
      "epoch # 113\n",
      "0.342917799949646\n",
      "epoch # 114\n",
      "0.3397393524646759\n",
      "epoch # 115\n",
      "0.3368634283542633\n",
      "epoch # 116\n",
      "0.3337242901325226\n",
      "epoch # 117\n",
      "0.3308626115322113\n",
      "epoch # 118\n",
      "0.3277609348297119\n",
      "epoch # 119\n",
      "0.32491812109947205\n",
      "epoch # 120\n",
      "0.3218541741371155\n",
      "epoch # 121\n",
      "0.31903284788131714\n",
      "epoch # 122\n",
      "0.31600645184516907\n",
      "epoch # 123\n",
      "0.313210129737854\n",
      "epoch # 124\n",
      "0.3102259933948517\n",
      "epoch # 125\n",
      "0.3074471652507782\n",
      "epoch # 126\n",
      "0.3045109510421753\n",
      "epoch # 127\n",
      "0.3018708825111389\n",
      "epoch # 128\n",
      "0.29924899339675903\n",
      "epoch # 129\n",
      "0.29686439037323\n",
      "epoch # 130\n",
      "0.2942778766155243\n",
      "epoch # 131\n",
      "0.2918252944946289\n",
      "epoch # 132\n",
      "0.28935492038726807\n",
      "epoch # 133\n",
      "0.28697144985198975\n",
      "epoch # 134\n",
      "0.2844642400741577\n",
      "epoch # 135\n",
      "0.2820694148540497\n",
      "epoch # 136\n",
      "0.27963802218437195\n",
      "epoch # 137\n",
      "0.27734947204589844\n",
      "epoch # 138\n",
      "0.27491244673728943\n",
      "epoch # 139\n",
      "0.2725870907306671\n",
      "epoch # 140\n",
      "0.2701853811740875\n",
      "epoch # 141\n",
      "0.26795604825019836\n",
      "epoch # 142\n",
      "0.2655830681324005\n",
      "epoch # 143\n",
      "0.26339221000671387\n",
      "epoch # 144\n",
      "0.2610956132411957\n",
      "epoch # 145\n",
      "0.2588954269886017\n",
      "epoch # 146\n",
      "0.25657761096954346\n",
      "epoch # 147\n",
      "0.254427045583725\n",
      "epoch # 148\n",
      "0.2521965205669403\n",
      "epoch # 149\n",
      "0.25008919835090637\n",
      "epoch # 150\n",
      "0.24782195687294006\n",
      "epoch # 151\n",
      "0.2458486706018448\n",
      "epoch # 152\n",
      "0.24361200630664825\n",
      "epoch # 153\n",
      "0.24160420894622803\n",
      "epoch # 154\n",
      "0.23938171565532684\n",
      "epoch # 155\n",
      "0.23744934797286987\n",
      "epoch # 156\n",
      "0.23530426621437073\n",
      "epoch # 157\n",
      "0.2334005981683731\n",
      "epoch # 158\n",
      "0.2312333881855011\n",
      "epoch # 159\n",
      "0.22935907542705536\n",
      "epoch # 160\n",
      "0.227308452129364\n",
      "epoch # 161\n",
      "0.2254311889410019\n",
      "epoch # 162\n",
      "0.22339078783988953\n",
      "epoch # 163\n",
      "0.22155945003032684\n",
      "epoch # 164\n",
      "0.21962572634220123\n",
      "epoch # 165\n",
      "0.21776443719863892\n",
      "epoch # 166\n",
      "0.21584831178188324\n",
      "epoch # 167\n",
      "0.21400171518325806\n",
      "epoch # 168\n",
      "0.21220920979976654\n",
      "epoch # 169\n",
      "0.2103874832391739\n",
      "epoch # 170\n",
      "0.20858702063560486\n",
      "epoch # 171\n",
      "0.20676694810390472\n",
      "epoch # 172\n",
      "0.20502986013889313\n",
      "epoch # 173\n",
      "0.20326901972293854\n",
      "epoch # 174\n",
      "0.20158234238624573\n",
      "epoch # 175\n",
      "0.19978825747966766\n",
      "epoch # 176\n",
      "0.1981993466615677\n",
      "epoch # 177\n",
      "0.19644419848918915\n",
      "epoch # 178\n",
      "0.19486916065216064\n",
      "epoch # 179\n",
      "0.19310356676578522\n",
      "epoch # 180\n",
      "0.1916305124759674\n",
      "epoch # 181\n",
      "0.18995368480682373\n",
      "epoch # 182\n",
      "0.18846920132637024\n",
      "epoch # 183\n",
      "0.18682223558425903\n",
      "epoch # 184\n",
      "0.18538470566272736\n",
      "epoch # 185\n",
      "0.1838163435459137\n",
      "epoch # 186\n",
      "0.1823301762342453\n",
      "epoch # 187\n",
      "0.1808086633682251\n",
      "epoch # 188\n",
      "0.17932865023612976\n",
      "epoch # 189\n",
      "0.17790545523166656\n",
      "epoch # 190\n",
      "0.17642031610012054\n",
      "epoch # 191\n",
      "0.17502200603485107\n",
      "epoch # 192\n",
      "0.1735796332359314\n",
      "epoch # 193\n",
      "0.17225614190101624\n",
      "epoch # 194\n",
      "0.17076905071735382\n",
      "epoch # 195\n",
      "0.16949200630187988\n",
      "epoch # 196\n",
      "0.1680234968662262\n",
      "epoch # 197\n",
      "0.16680991649627686\n",
      "epoch # 198\n",
      "0.1653841733932495\n",
      "epoch # 199\n",
      "0.16413061320781708\n",
      "epoch # 200\n",
      "0.1627974957227707\n",
      "epoch # 201\n",
      "0.1615549474954605\n",
      "epoch # 202\n",
      "0.16025298833847046\n",
      "epoch # 203\n",
      "0.15898722410202026\n",
      "epoch # 204\n",
      "0.15775159001350403\n",
      "epoch # 205\n",
      "0.1565079391002655\n",
      "epoch # 206\n",
      "0.15532507002353668\n",
      "epoch # 207\n",
      "0.15404817461967468\n",
      "epoch # 208\n",
      "0.15295372903347015\n",
      "epoch # 209\n",
      "0.15168628096580505\n",
      "epoch # 210\n",
      "0.15061137080192566\n",
      "epoch # 211\n",
      "0.14936475455760956\n",
      "epoch # 212\n",
      "0.1482871174812317\n",
      "epoch # 213\n",
      "0.1471247375011444\n",
      "epoch # 214\n",
      "0.14602859318256378\n",
      "epoch # 215\n",
      "0.1448991745710373\n",
      "epoch # 216\n",
      "0.14381572604179382\n",
      "epoch # 217\n",
      "0.1427595466375351\n",
      "epoch # 218\n",
      "0.1416454315185547\n",
      "epoch # 219\n",
      "0.1406276375055313\n",
      "epoch # 220\n",
      "0.139516681432724\n",
      "epoch # 221\n",
      "0.1385742574930191\n",
      "epoch # 222\n",
      "0.13746172189712524\n",
      "epoch # 223\n",
      "0.13651227951049805\n",
      "epoch # 224\n",
      "0.13546395301818848\n",
      "epoch # 225\n",
      "0.13451702892780304\n",
      "epoch # 226\n",
      "0.13350529968738556\n",
      "epoch # 227\n",
      "0.13253220915794373\n",
      "epoch # 228\n",
      "0.1315838247537613\n",
      "epoch # 229\n",
      "0.13061940670013428\n",
      "epoch # 230\n",
      "0.12971100211143494\n",
      "epoch # 231\n",
      "0.12871834635734558\n",
      "epoch # 232\n",
      "0.1278749704360962\n",
      "epoch # 233\n",
      "0.1269034594297409\n",
      "epoch # 234\n",
      "0.12606245279312134\n",
      "epoch # 235\n",
      "0.12511204183101654\n",
      "epoch # 236\n",
      "0.12427300959825516\n",
      "epoch # 237\n",
      "0.12338714301586151\n",
      "epoch # 238\n",
      "0.12252265959978104\n",
      "epoch # 239\n",
      "0.12167038023471832\n",
      "epoch # 240\n",
      "0.120810866355896\n",
      "epoch # 241\n",
      "0.12001851201057434\n",
      "epoch # 242\n",
      "0.11913279443979263\n",
      "epoch # 243\n",
      "0.11837317049503326\n",
      "epoch # 244\n",
      "0.11751055717468262\n",
      "epoch # 245\n",
      "0.11677004396915436\n",
      "epoch # 246\n",
      "0.11593043059110641\n",
      "epoch # 247\n",
      "0.1151660680770874\n",
      "epoch # 248\n",
      "0.11438675224781036\n",
      "epoch # 249\n",
      "0.11362084746360779\n",
      "epoch # 250\n",
      "0.11287032067775726\n",
      "epoch # 251\n",
      "0.1120835468173027\n",
      "epoch # 252\n",
      "0.11139094084501266\n",
      "epoch # 253\n",
      "0.11060556769371033\n",
      "epoch # 254\n",
      "0.10993137210607529\n",
      "epoch # 255\n",
      "0.10915721952915192\n",
      "epoch # 256\n",
      "0.10848920047283173\n",
      "epoch # 257\n",
      "0.10776349157094955\n",
      "epoch # 258\n",
      "0.10706723481416702\n",
      "epoch # 259\n",
      "0.1063743382692337\n",
      "epoch # 260\n",
      "0.10568326711654663\n",
      "epoch # 261\n",
      "0.10503740608692169\n",
      "epoch # 262\n",
      "0.10431884229183197\n",
      "epoch # 263\n",
      "0.10370411723852158\n",
      "epoch # 264\n",
      "0.10301037132740021\n",
      "epoch # 265\n",
      "0.1024014875292778\n",
      "epoch # 266\n",
      "0.1017252504825592\n",
      "epoch # 267\n",
      "0.1010982096195221\n",
      "epoch # 268\n",
      "0.10047593712806702\n",
      "epoch # 269\n",
      "0.09984265267848969\n",
      "epoch # 270\n",
      "0.09924087673425674\n",
      "epoch # 271\n",
      "0.09859165549278259\n",
      "epoch # 272\n",
      "0.09803255647420883\n",
      "epoch # 273\n",
      "0.09739819914102554\n",
      "epoch # 274\n",
      "0.09684595465660095\n",
      "epoch # 275\n",
      "0.09622574597597122\n",
      "epoch # 276\n",
      "0.09565732628107071\n",
      "epoch # 277\n",
      "0.09508061408996582\n",
      "epoch # 278\n",
      "0.09450039267539978\n",
      "epoch # 279\n",
      "0.0939575731754303\n",
      "epoch # 280\n",
      "0.09336698055267334\n",
      "epoch # 281\n",
      "0.09285847842693329\n",
      "epoch # 282\n",
      "0.09226981550455093\n",
      "epoch # 283\n",
      "0.09176751971244812\n",
      "epoch # 284\n",
      "0.09120763093233109\n",
      "epoch # 285\n",
      "0.0906866043806076\n",
      "epoch # 286\n",
      "0.090152308344841\n",
      "epoch # 287\n",
      "0.08963102847337723\n",
      "epoch # 288\n",
      "0.08912652730941772\n",
      "epoch # 289\n",
      "0.08859167248010635\n",
      "epoch # 290\n",
      "0.08812515437602997\n",
      "epoch # 291\n",
      "0.08758728951215744\n",
      "epoch # 292\n",
      "0.08711635321378708\n",
      "epoch # 293\n",
      "0.08661064505577087\n",
      "epoch # 294\n",
      "0.08613069355487823\n",
      "epoch # 295\n",
      "0.08564697206020355\n",
      "epoch # 296\n",
      "0.08516533672809601\n",
      "epoch # 297\n",
      "0.08470585942268372\n",
      "epoch # 298\n",
      "0.08421076089143753\n",
      "epoch # 299\n",
      "0.08378302305936813\n"
     ]
    }
   ],
   "source": [
    "losses = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,300),losses)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = Variable(torch.from_numpy(features_test)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1,  0,  0,  1,  0,  0,  1,  0,  0,  0,  1,  1,  0,\n",
       "         1,  0,  1,  1,  1,  0,  0,  0,  1,  1,  1,  0,  1,  1,\n",
       "         1,  1,  0,  1,  1,  1,  0,  0,  1,  0,  0,  0,  0,  1,\n",
       "         1,  0,  1,  0,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "predictions = torch.max(net(x_test), 1)[1]\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(labels_test, predictions.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Variable(torch.Tensor([ [200, 440]])).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1,  0,  0,  1,  0,  0,  1,  0,  0,  0,  1,  1,  0,\n",
       "         1,  0,  1,  1,  1,  0,  0,  0,  1,  1,  1,  0,  1,  1,\n",
       "         1,  1,  0,  1,  1,  1,  0,  0,  1,  0,  0,  0,  0,  1,\n",
       "         1,  0,  1,  0,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x_test).max(dim=1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 200.,  440.]])"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 200.,  440.]])"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0])"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(test).max(dim=1)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let us learn another function f(x) = x^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_for_x_sq():\n",
    "    # Given f(x) = x*x, is_f_x defines whether the function is satisfied\n",
    "    data = []\n",
    "    for i in range(1,100):\n",
    "        data.append((i, i*i, 1)) # True\n",
    "    for j in range(100, 201):\n",
    "        data.append((j, 2*j, 0)) # Not true\n",
    "    column_names = [\"first_number\",\"f_x\", \"is_f_x\"]\n",
    "    df = pd.DataFrame(data, columns=column_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = build_dataset_for_x_sq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_number</th>\n",
       "      <th>f_x</th>\n",
       "      <th>is_f_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_number  f_x  is_f_x\n",
       "0             1    1       1\n",
       "1             2    4       1\n",
       "2             3    9       1\n",
       "3             4   16       1\n",
       "4             5   25       1"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df2.is_f_x.values\n",
    "features = df2.drop(columns=['is_f_x']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, shuffle=True, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    net.train()\n",
    "    net.r\n",
    "    losses = []\n",
    "    for epoch in range(1,300):\n",
    "        x_train = Variable(torch.from_numpy(features_train)).float()\n",
    "        y_train = Variable(torch.from_numpy(labels_train)).long()\n",
    "        y_pred = net(x_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        print (\"epoch #\", epoch)\n",
    "        print (loss.item())\n",
    "        losses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch # 1\n",
      "0.08329461514949799\n",
      "epoch # 2\n",
      "0.08285661786794662\n",
      "epoch # 3\n",
      "0.08239830285310745\n",
      "epoch # 4\n",
      "0.08194900304079056\n",
      "epoch # 5\n",
      "0.08150509744882584\n",
      "epoch # 6\n",
      "0.081052765250206\n",
      "epoch # 7\n",
      "0.08063855767250061\n",
      "epoch # 8\n",
      "0.08017837256193161\n",
      "epoch # 9\n",
      "0.07976789027452469\n",
      "epoch # 10\n",
      "0.07932697981595993\n",
      "epoch # 11\n",
      "0.07891629636287689\n",
      "epoch # 12\n",
      "0.0784917101264\n",
      "epoch # 13\n",
      "0.07807154953479767\n",
      "epoch # 14\n",
      "0.07767486572265625\n",
      "epoch # 15\n",
      "0.0772501528263092\n",
      "epoch # 16\n",
      "0.07686851918697357\n",
      "epoch # 17\n",
      "0.07644809037446976\n",
      "epoch # 18\n",
      "0.07606522738933563\n",
      "epoch # 19\n",
      "0.07566791027784348\n",
      "epoch # 20\n",
      "0.07527634501457214\n",
      "epoch # 21\n",
      "0.07489403337240219\n",
      "epoch # 22\n",
      "0.07450174540281296\n",
      "epoch # 23\n",
      "0.0741441622376442\n",
      "epoch # 24\n",
      "0.07374756783246994\n",
      "epoch # 25\n",
      "0.07338841259479523\n",
      "epoch # 26\n",
      "0.07301128655672073\n",
      "epoch # 27\n",
      "0.0726504847407341\n",
      "epoch # 28\n",
      "0.0722862035036087\n",
      "epoch # 29\n",
      "0.07191790640354156\n",
      "epoch # 30\n",
      "0.0715765431523323\n",
      "epoch # 31\n",
      "0.07120854407548904\n",
      "epoch # 32\n",
      "0.07087407261133194\n",
      "epoch # 33\n",
      "0.07051141560077667\n",
      "epoch # 34\n",
      "0.07017716020345688\n",
      "epoch # 35\n",
      "0.06983330845832825\n",
      "epoch # 36\n",
      "0.0694895088672638\n",
      "epoch # 37\n",
      "0.0691593587398529\n",
      "epoch # 38\n",
      "0.06881693750619888\n",
      "epoch # 39\n",
      "0.0685051754117012\n",
      "epoch # 40\n",
      "0.06816153228282928\n",
      "epoch # 41\n",
      "0.06784479320049286\n",
      "epoch # 42\n",
      "0.06752036511898041\n",
      "epoch # 43\n",
      "0.06720098108053207\n",
      "epoch # 44\n",
      "0.06688698381185532\n",
      "epoch # 45\n",
      "0.06656204164028168\n",
      "epoch # 46\n",
      "0.06626641005277634\n",
      "epoch # 47\n",
      "0.06594562530517578\n",
      "epoch # 48\n",
      "0.06564927846193314\n",
      "epoch # 49\n",
      "0.06533606350421906\n",
      "epoch # 50\n",
      "0.0650397390127182\n",
      "epoch # 51\n",
      "0.0647425577044487\n",
      "epoch # 52\n",
      "0.0644378662109375\n",
      "epoch # 53\n",
      "0.06415200233459473\n",
      "epoch # 54\n",
      "0.06384842097759247\n",
      "epoch # 55\n",
      "0.06357322633266449\n",
      "epoch # 56\n",
      "0.06327709555625916\n",
      "epoch # 57\n",
      "0.06299738585948944\n",
      "epoch # 58\n",
      "0.06271354854106903\n",
      "epoch # 59\n",
      "0.06242752820253372\n",
      "epoch # 60\n",
      "0.06215906888246536\n",
      "epoch # 61\n",
      "0.061869632452726364\n",
      "epoch # 62\n",
      "0.06161065399646759\n",
      "epoch # 63\n",
      "0.06133204698562622\n",
      "epoch # 64\n",
      "0.06106375902891159\n",
      "epoch # 65\n",
      "0.060795821249485016\n",
      "epoch # 66\n",
      "0.060526344925165176\n",
      "epoch # 67\n",
      "0.0602700375020504\n",
      "epoch # 68\n",
      "0.05999789014458656\n",
      "epoch # 69\n",
      "0.059751275926828384\n",
      "epoch # 70\n",
      "0.05948683246970177\n",
      "epoch # 71\n",
      "0.059233035892248154\n",
      "epoch # 72\n",
      "0.05898246914148331\n",
      "epoch # 73\n",
      "0.058725833892822266\n",
      "epoch # 74\n",
      "0.05848297104239464\n",
      "epoch # 75\n",
      "0.058222655206918716\n",
      "epoch # 76\n",
      "0.05799085646867752\n",
      "epoch # 77\n",
      "0.057738106697797775\n",
      "epoch # 78\n",
      "0.057499490678310394\n",
      "epoch # 79\n",
      "0.05726154148578644\n",
      "epoch # 80\n",
      "0.057014934718608856\n",
      "epoch # 81\n",
      "0.05678648501634598\n",
      "epoch # 82\n",
      "0.056541189551353455\n",
      "epoch # 83\n",
      "0.05631786212325096\n",
      "epoch # 84\n",
      "0.056080982089042664\n",
      "epoch # 85\n",
      "0.055852439254522324\n",
      "epoch # 86\n",
      "0.05562622845172882\n",
      "epoch # 87\n",
      "0.0553910955786705\n",
      "epoch # 88\n",
      "0.05517696961760521\n",
      "epoch # 89\n",
      "0.05494188144803047\n",
      "epoch # 90\n",
      "0.05473019927740097\n",
      "epoch # 91\n",
      "0.054504554718732834\n",
      "epoch # 92\n",
      "0.05428653210401535\n",
      "epoch # 93\n",
      "0.054072145372629166\n",
      "epoch # 94\n",
      "0.053850047290325165\n",
      "epoch # 95\n",
      "0.053646646440029144\n",
      "epoch # 96\n",
      "0.05342290922999382\n",
      "epoch # 97\n",
      "0.05321894586086273\n",
      "epoch # 98\n",
      "0.05300721526145935\n",
      "epoch # 99\n",
      "0.052796266973018646\n",
      "epoch # 100\n",
      "0.05259563401341438\n",
      "epoch # 101\n",
      "0.0523819774389267\n",
      "epoch # 102\n",
      "0.052188169211149216\n",
      "epoch # 103\n",
      "0.05197608098387718\n",
      "epoch # 104\n",
      "0.05178123340010643\n",
      "epoch # 105\n",
      "0.05157946050167084\n",
      "epoch # 106\n",
      "0.05137874186038971\n",
      "epoch # 107\n",
      "0.051188692450523376\n",
      "epoch # 108\n",
      "0.05098189041018486\n",
      "epoch # 109\n",
      "0.05079864338040352\n",
      "epoch # 110\n",
      "0.05059945955872536\n",
      "epoch # 111\n",
      "0.050408463925123215\n",
      "epoch # 112\n",
      "0.05022098124027252\n",
      "epoch # 113\n",
      "0.05002588406205177\n",
      "epoch # 114\n",
      "0.04984625428915024\n",
      "epoch # 115\n",
      "0.04964972287416458\n",
      "epoch # 116\n",
      "0.04947330802679062\n",
      "epoch # 117\n",
      "0.04928413778543472\n",
      "epoch # 118\n",
      "0.049100350588560104\n",
      "epoch # 119\n",
      "0.04892394319176674\n",
      "epoch # 120\n",
      "0.0487336702644825\n",
      "epoch # 121\n",
      "0.048565611243247986\n",
      "epoch # 122\n",
      "0.04837910830974579\n",
      "epoch # 123\n",
      "0.048205576837062836\n",
      "epoch # 124\n",
      "0.04802965372800827\n",
      "epoch # 125\n",
      "0.047850772738456726\n",
      "epoch # 126\n",
      "0.047683969140052795\n",
      "epoch # 127\n",
      "0.047502171248197556\n",
      "epoch # 128\n",
      "0.04734043404459953\n",
      "epoch # 129\n",
      "0.04716363176703453\n",
      "epoch # 130\n",
      "0.04699542745947838\n",
      "epoch # 131\n",
      "0.04683055356144905\n",
      "epoch # 132\n",
      "0.04665482044219971\n",
      "epoch # 133\n",
      "0.0464995838701725\n",
      "epoch # 134\n",
      "0.046326346695423126\n",
      "epoch # 135\n",
      "0.04616639390587807\n",
      "epoch # 136\n",
      "0.0460023395717144\n",
      "epoch # 137\n",
      "0.04583730548620224\n",
      "epoch # 138\n",
      "0.04568200930953026\n",
      "epoch # 139\n",
      "0.045513857156038284\n",
      "epoch # 140\n",
      "0.04536372795701027\n",
      "epoch # 141\n",
      "0.045199789106845856\n",
      "epoch # 142\n",
      "0.045043520629405975\n",
      "epoch # 143\n",
      "0.04489060491323471\n",
      "epoch # 144\n",
      "0.044727034866809845\n",
      "epoch # 145\n",
      "0.044583648443222046\n",
      "epoch # 146\n",
      "0.044422682374715805\n",
      "epoch # 147\n",
      "0.044273220002651215\n",
      "epoch # 148\n",
      "0.04412179812788963\n",
      "epoch # 149\n",
      "0.0439673587679863\n",
      "epoch # 150\n",
      "0.04382393881678581\n",
      "epoch # 151\n",
      "0.04366792365908623\n",
      "epoch # 152\n",
      "0.04353255406022072\n",
      "epoch # 153\n",
      "0.043383318930864334\n",
      "epoch # 154\n",
      "0.04324060678482056\n",
      "epoch # 155\n",
      "0.04310322925448418\n",
      "epoch # 156\n",
      "0.04295317083597183\n",
      "epoch # 157\n",
      "0.042823199182748795\n",
      "epoch # 158\n",
      "0.04267716780304909\n",
      "epoch # 159\n",
      "0.0425395593047142\n",
      "epoch # 160\n",
      "0.042404256761074066\n",
      "epoch # 161\n",
      "0.042260050773620605\n",
      "epoch # 162\n",
      "0.042133234441280365\n",
      "epoch # 163\n",
      "0.04199031740427017\n",
      "epoch # 164\n",
      "0.041859205812215805\n",
      "epoch # 165\n",
      "0.04172477126121521\n",
      "epoch # 166\n",
      "0.041585925966501236\n",
      "epoch # 167\n",
      "0.04146304726600647\n",
      "epoch # 168\n",
      "0.04132245481014252\n",
      "epoch # 169\n",
      "0.04119651019573212\n",
      "epoch # 170\n",
      "0.04106523469090462\n",
      "epoch # 171\n",
      "0.040930427610874176\n",
      "epoch # 172\n",
      "0.04080992937088013\n",
      "epoch # 173\n",
      "0.040674056857824326\n",
      "epoch # 174\n",
      "0.0405513197183609\n",
      "epoch # 175\n",
      "0.0404231883585453\n",
      "epoch # 176\n",
      "0.040293190628290176\n",
      "epoch # 177\n",
      "0.04017460346221924\n",
      "epoch # 178\n",
      "0.04004271328449249\n",
      "epoch # 179\n",
      "0.03992411121726036\n",
      "epoch # 180\n",
      "0.03979838266968727\n",
      "epoch # 181\n",
      "0.03967193141579628\n",
      "epoch # 182\n",
      "0.03955736383795738\n",
      "epoch # 183\n",
      "0.03942829743027687\n",
      "epoch # 184\n",
      "0.03931237384676933\n",
      "epoch # 185\n",
      "0.03919122740626335\n",
      "epoch # 186\n",
      "0.03906680643558502\n",
      "epoch # 187\n",
      "0.03895572945475578\n",
      "epoch # 188\n",
      "0.03883086144924164\n",
      "epoch # 189\n",
      "0.03871653601527214\n",
      "epoch # 190\n",
      "0.038599371910095215\n",
      "epoch # 191\n",
      "0.038478583097457886\n",
      "epoch # 192\n",
      "0.03836938366293907\n",
      "epoch # 193\n",
      "0.03824862837791443\n",
      "epoch # 194\n",
      "0.03813633695244789\n",
      "epoch # 195\n",
      "0.03802322596311569\n",
      "epoch # 196\n",
      "0.037905313074588776\n",
      "epoch # 197\n",
      "0.037798620760440826\n",
      "epoch # 198\n",
      "0.03768172487616539\n",
      "epoch # 199\n",
      "0.03757042810320854\n",
      "epoch # 200\n",
      "0.037462592124938965\n",
      "epoch # 201\n",
      "0.03734660521149635\n",
      "epoch # 202\n",
      "0.037241868674755096\n",
      "epoch # 203\n",
      "0.037129957228899\n",
      "epoch # 204\n",
      "0.03701906278729439\n",
      "epoch # 205\n",
      "0.03691592067480087\n",
      "epoch # 206\n",
      "0.03680327534675598\n",
      "epoch # 207\n",
      "0.03669911250472069\n",
      "epoch # 208\n",
      "0.036592379212379456\n",
      "epoch # 209\n",
      "0.036483462899923325\n",
      "epoch # 210\n",
      "0.03638284280896187\n",
      "epoch # 211\n",
      "0.03627436235547066\n",
      "epoch # 212\n",
      "0.0361710749566555\n",
      "epoch # 213\n",
      "0.036069270223379135\n",
      "epoch # 214\n",
      "0.035962991416454315\n",
      "epoch # 215\n",
      "0.035864293575286865\n",
      "epoch # 216\n",
      "0.03576035052537918\n",
      "epoch # 217\n",
      "0.03565752133727074\n",
      "epoch # 218\n",
      "0.03556199371814728\n",
      "epoch # 219\n",
      "0.03545796126127243\n",
      "epoch # 220\n",
      "0.035360731184482574\n",
      "epoch # 221\n",
      "0.03526286035776138\n",
      "epoch # 222\n",
      "0.03516228124499321\n",
      "epoch # 223\n",
      "0.03506901115179062\n",
      "epoch # 224\n",
      "0.03497099131345749\n",
      "epoch # 225\n",
      "0.034873805940151215\n",
      "epoch # 226\n",
      "0.03478274494409561\n",
      "epoch # 227\n",
      "0.03468580171465874\n",
      "epoch # 228\n",
      "0.034593984484672546\n",
      "epoch # 229\n",
      "0.03450245037674904\n",
      "epoch # 230\n",
      "0.034407950937747955\n",
      "epoch # 231\n",
      "0.03432057425379753\n",
      "epoch # 232\n",
      "0.034229032695293427\n",
      "epoch # 233\n",
      "0.034138429909944534\n",
      "epoch # 234\n",
      "0.03405354544520378\n",
      "epoch # 235\n",
      "0.03396249935030937\n",
      "epoch # 236\n",
      "0.03387707844376564\n",
      "epoch # 237\n",
      "0.033791616559028625\n",
      "epoch # 238\n",
      "0.03370250388979912\n",
      "epoch # 239\n",
      "0.03362155333161354\n",
      "epoch # 240\n",
      "0.033535029739141464\n",
      "epoch # 241\n",
      "0.033449385315179825\n",
      "epoch # 242\n",
      "0.03336992859840393\n",
      "epoch # 243\n",
      "0.03328320384025574\n",
      "epoch # 244\n",
      "0.03320229798555374\n",
      "epoch # 245\n",
      "0.033121507614851\n",
      "epoch # 246\n",
      "0.03303656727075577\n",
      "epoch # 247\n",
      "0.032959237694740295\n",
      "epoch # 248\n",
      "0.032876744866371155\n",
      "epoch # 249\n",
      "0.032794300466775894\n",
      "epoch # 250\n",
      "0.03271951526403427\n",
      "epoch # 251\n",
      "0.032635968178510666\n",
      "epoch # 252\n",
      "0.03255786374211311\n",
      "epoch # 253\n",
      "0.03248108923435211\n",
      "epoch # 254\n",
      "0.03239930793642998\n",
      "epoch # 255\n",
      "0.03232445567846298\n",
      "epoch # 256\n",
      "0.03224622458219528\n",
      "epoch # 257\n",
      "0.03216630965471268\n",
      "epoch # 258\n",
      "0.032094016671180725\n",
      "epoch # 259\n",
      "0.03201495110988617\n",
      "epoch # 260\n",
      "0.031937845051288605\n",
      "epoch # 261\n",
      "0.031866006553173065\n",
      "epoch # 262\n",
      "0.03178695961833\n",
      "epoch # 263\n",
      "0.03171366825699806\n",
      "epoch # 264\n",
      "0.031640198081731796\n",
      "epoch # 265\n",
      "0.03156297281384468\n",
      "epoch # 266\n",
      "0.03149176016449928\n",
      "epoch # 267\n",
      "0.03141767531633377\n",
      "epoch # 268\n",
      "0.03134250268340111\n",
      "epoch # 269\n",
      "0.031272757798433304\n",
      "epoch # 270\n",
      "0.031198300421237946\n",
      "epoch # 271\n",
      "0.03112511709332466\n",
      "epoch # 272\n",
      "0.031056562438607216\n",
      "epoch # 273\n",
      "0.03098239004611969\n",
      "epoch # 274\n",
      "0.030911238864064217\n",
      "epoch # 275\n",
      "0.03084282949566841\n",
      "epoch # 276\n",
      "0.030769720673561096\n",
      "epoch # 277\n",
      "0.030700422823429108\n",
      "epoch # 278\n",
      "0.030631570145487785\n",
      "epoch # 279\n",
      "0.030560389161109924\n",
      "epoch # 280\n",
      "0.030492233112454414\n",
      "epoch # 281\n",
      "0.030423393473029137\n",
      "epoch # 282\n",
      "0.030353650450706482\n",
      "epoch # 283\n",
      "0.030286753550171852\n",
      "epoch # 284\n",
      "0.030218476429581642\n",
      "epoch # 285\n",
      "0.030149536207318306\n",
      "epoch # 286\n",
      "0.030084116384387016\n",
      "epoch # 287\n",
      "0.03001631796360016\n",
      "epoch # 288\n",
      "0.02994818426668644\n",
      "epoch # 289\n",
      "0.029883991926908493\n",
      "epoch # 290\n",
      "0.02981693670153618\n",
      "epoch # 291\n",
      "0.02974967285990715\n",
      "epoch # 292\n",
      "0.029686640948057175\n",
      "epoch # 293\n",
      "0.029620110988616943\n",
      "epoch # 294\n",
      "0.029553823173046112\n",
      "epoch # 295\n",
      "0.029492134228348732\n",
      "epoch # 296\n",
      "0.029425764456391335\n",
      "epoch # 297\n",
      "0.02936086617410183\n",
      "epoch # 298\n",
      "0.029299672693014145\n",
      "epoch # 299\n",
      "0.029234176501631737\n"
     ]
    }
   ],
   "source": [
    "a = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = Variable(torch.from_numpy(features_test)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels_test,net(x_test).max(dim=1)[1].data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Variable(torch.Tensor([ [90, 90*91]])).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1])"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(test).max(dim=1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = Variable(torch.from_numpy(features_train)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9933333333333333"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels_train, net(x_train).max(dim=1)[1].data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_x(x):\n",
    "    return x * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_x(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
